LLM.cs

using TalkBack.Exceptions;
using TalkBack.Interfaces;
using Microsoft.Extensions.Logging;

namespace TalkBack;

public class LLM : ILLM
{
    private readonly ILogger<LLM> _logger;
    private ILLMProvider? _selectedProvider;

    public LLM(ILogger<LLM> logger)
    {
        _logger = logger;
    }

    public ILLMProvider? Provider => _selectedProvider;

    public void SetProvider(ILLMProvider provider)
    {
        _logger.LogDebug($"SetProvider to: {provider.Name}");
        _selectedProvider = provider;
    }

    public IConversationContext? CreateNewContext()
    {
        _logger.LogDebug("CreateNewContext");
        EnsureProvider();
        return _selectedProvider!.CreateNewContext();
    }

    public async Task StreamCompletionAsync(ICompletionReceiver receiver, string prompt, IConversationContext? context = null)
    {
        _logger.LogDebug($"StreamCompletionAsync - {prompt}");
        EnsureProvider();
        await _selectedProvider!.StreamCompletionAsync(receiver, prompt, context);
    }

    public async Task<IModelResponse> CompleteAsync(string prompt, IConversationContext? context = null)
    {
        _logger.LogDebug($"CompleteAsync - {prompt}");
        EnsureProvider();
        return await _selectedProvider!.CompleteAsync(prompt, context);
    }

    private void EnsureProvider()
    {
        if (_selectedProvider == null)
        {
            throw new NoProviderSetException();
        }
    }
}



ProviderActivator.cs

using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using TalkBack.Interfaces;

namespace TalkBack;

public class ProviderActivator : IProviderActivator
{
    private readonly ILogger _logger;
    private readonly IServiceProvider _serviceProvider;

    public ProviderActivator(ILogger<ProviderActivator> logger, IServiceProvider serviceProvider)
    {
        _logger = logger;
        _serviceProvider = serviceProvider;
    }

    public ILLMProvider? CreateProvider<T>() where T : ILLMProvider
    {
        _logger.LogDebug($"Create provider for {typeof(T).Name}");
        try
        {
            return _serviceProvider.GetService<T>();
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, $"Error creating instance of LLM provider type {typeof(T).Name}");
            throw;
        }
    }

}




Exceptions\InvalidConversationContextException.cs

namespace TalkBack.Exceptions;

[Serializable]
public class InvalidConversationContextException : Exception
{
	public InvalidConversationContextException() { }
	public InvalidConversationContextException(string message) : base(message) { }
	public InvalidConversationContextException(string message, Exception inner) : base(message, inner) { }

}



Exceptions\InvalidOptionsException.cs

namespace TalkBack.Exceptions;

[Serializable]
public class InvalidOptionsException : Exception
{
	public InvalidOptionsException() { }
	public InvalidOptionsException(string message) : base(message) { }
	public InvalidOptionsException(string message, Exception inner) : base(message, inner) { }
}



Exceptions\NoProviderSetException.cs

namespace TalkBack.Exceptions;

[Serializable]
public class NoProviderSetException : Exception
{
	public NoProviderSetException() { }
	public NoProviderSetException(string message) : base(message) { }
	public NoProviderSetException(string message, Exception inner) : base(message, inner) { }
}



Interfaces\ICompletionCallback.cs

namespace TalkBack.Interfaces;

public interface ICompletionCallback
{
    void Complete(string provider, string options, string prompt, string response);
}




Interfaces\ICompletionReceiver.cs

namespace TalkBack.Interfaces;

public interface ICompletionReceiver
{
    public Task ReceiveCompletionPartAsync(IModelResponse response, bool final);
}



Interfaces\IConversationContext.cs

using TalkBack.Models;

namespace TalkBack.Interfaces;
public interface IConversationContext
{
    string SystemPrompt { get; set; }
    void SetCompletionCallback(ICompletionCallback completionCallback);
    IEnumerable<ConversationItem> GetConverstationHistory();
}




Interfaces\IHttpHandler.cs

using System.Net.Http.Headers;

namespace TalkBack.Interfaces;

public interface IHttpHandler
{
    HttpRequestHeaders DefaultRequestHeaders { get; }
    HttpResponseMessage Get(string url);
    HttpResponseMessage Post(string url, HttpContent content);
    Task<HttpResponseMessage> GetAsync(string url);
    Task<HttpResponseMessage> PostAsync(string url, HttpContent content);
    Task<HttpResponseMessage> SendAsync(HttpRequestMessage msg, HttpCompletionOption competion);
}




Interfaces\ILLM.cs

namespace TalkBack.Interfaces;

public interface ILLM
{
    ILLMProvider? Provider { get; }
    void SetProvider(ILLMProvider provider);
    IConversationContext? CreateNewContext();
    Task StreamCompletionAsync(ICompletionReceiver receiver, string prompt, IConversationContext? context = null);
    Task<IModelResponse> CompleteAsync(string prompt, IConversationContext? context = null);
}




Interfaces\ILLMModel.cs

namespace TalkBack.Interfaces;

public interface ILLMModel
{
    string? Name { get; }
    string? Description { get; }
    string? Owner { get; }
    int ContextWindow { get; }
    bool SupportsImages { get; }
}




Interfaces\ILLMProvider.cs

using TalkBack.Models;

namespace TalkBack.Interfaces;

public interface ILLMProvider
{
    public string Name { get; }
    bool SupportsStreaming { get; }

    void InitProvider(IProviderOptions? options);
    public IConversationContext CreateNewContext(string? systemPrompt = null);
    Task<IModelResponse> CompleteAsync(string prompt, IConversationContext? context, List<ImageUrl>? imageUrls = null);
    Task StreamCompletionAsync(ICompletionReceiver receiver, string prompt, IConversationContext? context, List<ImageUrl>? imageUrls = null);
    Task<List<ILLMModel>> GetModelsAsync();
}




Interfaces\IModelResponse.cs

namespace TalkBack.Interfaces;

public interface IModelResponse
{
    string? Response { get; }
    IConversationContext? Context { get; }
}




Interfaces\IProviderActivator.cs

namespace TalkBack.Interfaces;

public interface IProviderActivator
{
    ILLMProvider? CreateProvider<T>() where T : ILLMProvider;
}




Interfaces\IProviderOptions.cs

namespace TalkBack.Interfaces;
public interface IProviderOptions
{
    
}




LLMProviders\Claude\ClaudeContentDelta.cs

using System.Text.Json.Serialization;

namespace TalkBack.LLMProviders.Claude;

internal class ClaudeContentDelta
{
    [JsonPropertyName("type")]
    public string Type { get; set; } = string.Empty;
    [JsonPropertyName("text")]
    public string Text { get; set; } = string.Empty;
}




LLMProviders\Claude\ClaudeContext.cs

using TalkBack.Interfaces;
using TalkBack.Models;

namespace TalkBack.LLMProviders.Claude;

internal class ClaudeContext : IConversationContext
{
    public List<ConversationItem> ContextData { get; set; } = new List<ConversationItem>();
    public string SystemPrompt { get; set; } = string.Empty;
    public string PartialResponse { get; set; } = string.Empty;
    public string CurrentPrompt { get; set; } = string.Empty;

    internal ICompletionCallback? CompletionCallback { get; set; } = null;

    public IEnumerable<ConversationItem> GetConverstationHistory()
    {
        return ContextData;
    }

    public void SetCompletionCallback(ICompletionCallback completionCallback)
    {
        CompletionCallback = completionCallback;
    }

}




LLMProviders\Claude\ClaudeMessage.cs

using System.Text.Json.Serialization;

namespace TalkBack.LLMProviders.Claude;

public class ClaudeMessage
{
    [JsonPropertyName("role")]
    public string Role { get; set; } = string.Empty;
    [JsonPropertyName("content")]
    public string Content { get; set; } = string.Empty;
}




LLMProviders\Claude\ClaudeMessageResponse.cs

using System.Text.Json.Serialization;

namespace TalkBack.LLMProviders.Claude;

public class ClaudeMessageResponse
{
    [JsonPropertyName("content")]
    public ClaudeMessageItem[]? Content { get; set; }
    [JsonPropertyName("stop_reason")]
    public string? StopReason { get; set; }
    [JsonPropertyName("stop_sequence")]
    public string? StopSequence { get; set; }
    [JsonPropertyName("model")]
    public string? Model { get; set; }
    [JsonPropertyName("role")]
    public string? Role { get; set; }
    [JsonPropertyName("type")]
    public string? Type { get; set; }
    [JsonPropertyName("id")]
    public string? Id { get; set; }
}

public class ClaudeMessageItem
{
    [JsonPropertyName("text")]
    public string? Text { get; set; }
    [JsonPropertyName("type")]
    public string? Type { get; set; }

}



LLMProviders\Claude\ClaudeModel.cs

using TalkBack.Interfaces;

namespace TalkBack.LLMProviders.Claude;

public class ClaudeModel : ILLMModel
{
    public string? Name { get; set; }

    public string? Description { get; set; }

    public string? Owner { get; set; }

    public int ContextWindow { get; set; }

    public bool SupportsImages { get; set; }
}




LLMProviders\Claude\ClaudeOptions.cs

using TalkBack.Interfaces;

namespace TalkBack.LLMProviders.Claude;

public class ClaudeOptions : IProviderOptions
{
    /// <summary>
    ///  Model parameters: https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values
    /// </summary>

    // Required options
    public string? Model { get; set; }
    public string? AnthropicVersion { get; set; } = "2023-06-01";
    public string? ApiKey { get; set; }
    public string AuthToken { get; set; } = string.Empty;
    public int MaxTokensToSample { get; set; } = 256;


    // Optional options
    public string[]? StopSequences { get; set; }
    public float Temperature { get; set; }
    public float TopP { get; set; }
    public int TopK { get; set; }
}




LLMProviders\Claude\ClaudeParameters.cs

using System.Text.Json.Serialization;

namespace TalkBack.LLMProviders.Claude;

public class ClaudeParameters
{
    [JsonPropertyName("model")]
    public string? Model { get; set; }
    [JsonPropertyName("max_tokens")]
    public int MaxTokens { get; set; } = 4096;
    // Optional options
    [JsonPropertyName("stream")]
    public bool Stream { get; set; } = false;
    [JsonPropertyName("messages")]
    public List<ClaudeMessage> Messages { get; set; } = new List<ClaudeMessage>();
}




LLMProviders\Claude\ClaudeProvider.cs

using TalkBack.Exceptions;
using TalkBack.Interfaces;
using TalkBack.Models;
using Microsoft.Extensions.Logging;
using System.Reactive.Linq;
using System.Text;
using System.Text.Json;
using System.Diagnostics;
using System.Reflection;

namespace TalkBack.LLMProviders.Claude;

/// <summary>
/// Claude API docs: https://docs.anthropic.com/claude/reference/getting-started-with-the-api
/// </summary>
public class ClaudeProvider : ILLMProvider
{
    private readonly ILogger<ClaudeProvider> _logger;
    private readonly IHttpHandler _httpHandler;
    private ClaudeOptions? _options;

    public ClaudeProvider(ILogger<ClaudeProvider> logger, IHttpHandler httpHandler)
    {
        _logger = logger;
        _httpHandler = httpHandler;
    }

    public bool SupportsStreaming => true;

    public string Name => "Claude";

    public void InitProvider(IProviderOptions? options)
    {
        _logger.LogDebug("Initializing ClaudeProvider with provided options.");
        if (_options != null)
        {
            throw new InvalidOptionsException("You can only initialize the ClaudeProvider once!");
        }
        _options = options as ClaudeOptions;
        if (_options is null)
        {
            _options = null;
            throw new InvalidOptionsException("The Claude Provider requires an instance of the ClaudeOptions class with a valid Model!");
        }
        if (string.IsNullOrEmpty(_options.Model))
        {
            throw new InvalidOptionsException("The Claude Provider requires an instance of the ClaudeOptions class with a valid Model!");
        }
        _httpHandler.DefaultRequestHeaders.Add("anthropic-version", _options.AnthropicVersion);
        _httpHandler.DefaultRequestHeaders.Add("x-api-key", _options.ApiKey);
    }

    public async Task<IModelResponse> CompleteAsync(string prompt, IConversationContext? context = null, List<ImageUrl>? imageUrls = null)
    {
        if (_options is null)
        {
            throw new InvalidOperationException("You must Init the provider first.");
        }
        if (context is null)
        {
            context = new ClaudeContext();
        }
        if (context is null || context is not ClaudeContext)
        {
            throw new InvalidConversationContextException("Received an invalid context.");
        }
        var messages = GenerateMessages(context, prompt);
        ClaudeParameters parameters = GenerateParameters(messages, context as ClaudeContext, false);
        var jsonContent = JsonSerializer.Serialize(parameters);
        var content = new StringContent(jsonContent, Encoding.UTF8, "application/json");
        var response = await _httpHandler.PostAsync("https://api.anthropic.com/v1/messages", content);
        if (!response.IsSuccessStatusCode)
        {
            throw new Exception($"{response.StatusCode} - {response.ReasonPhrase}");
        }
        var result = await response.Content.ReadAsStringAsync();

        if (context is null)
        {
            context = new ClaudeContext();
        }
        var responseOb = JsonSerializer.Deserialize<ClaudeMessageResponse>(result);

        if ((context as ClaudeContext)!.CompletionCallback is not null)
        {
            (context as ClaudeContext)!.CompletionCallback!.Complete(Name, $"Model: {parameters.Model}", prompt, responseOb?.Content?[0].Text ?? string.Empty);
        }
        (context as ClaudeContext)!.ContextData.Add(new ConversationItem { User = prompt, Assistant = responseOb!.Content?[0].Text ?? "" });

        return new ClaudeResponse()
        {
            Response = responseOb?.Content?[0].Text ?? string.Empty,
            Context = context
        };
    }

    public async Task StreamCompletionAsync(ICompletionReceiver receiver, string prompt, IConversationContext? context = null, List<ImageUrl>? imageUrls = null)
    {
        if (_options is null)
        {
            throw new InvalidOperationException("You must Init the model first.");
        }
        if (context is not null && context is not ClaudeContext)
        {
            throw new InvalidConversationContextException("Received an invalid context.");
        }
        if (context is null)
        {
            context = new ClaudeContext();
        }
        (context as ClaudeContext)!.CurrentPrompt = prompt;
        (context as ClaudeContext)!.PartialResponse = string.Empty;

        var messages = GenerateMessages(context, prompt);
        ClaudeParameters parameters = GenerateParameters(messages, context as ClaudeContext, true);
        var jsonContent = JsonSerializer.Serialize(parameters);
        var content = new StringContent(jsonContent, Encoding.UTF8, "application/json");
        content.Headers.Add("anthropic-version", "2023-06-01");
        content.Headers.Add("x-api-key", _options.ApiKey);
        var response = await _httpHandler.PostAsync("https://api.anthropic.com/v1/messages", content);


        if (response.IsSuccessStatusCode)
        {
            // Read the SSE stream from the response.
            var sseStream = await response.Content.ReadAsStreamAsync();

            // Create an observable sequence from the SSE stream.
            var sseObservable = Observable.Using(
                () => new StreamReader(sseStream, Encoding.UTF8),
                streamReader => Observable.Create<string>(
                    async (observer, cancellationToken) =>
                    {
                        try
                        {
                            while (!cancellationToken.IsCancellationRequested)
                            {
                                string? line = await streamReader.ReadLineAsync();
                                if (line == null)
                                    break;

                                observer.OnNext(line);
                            }
                            observer.OnCompleted();
                        }
                        catch (Exception ex)
                        {
                            observer.OnError(ex);
                        }
                    }));

            String workingResponse = string.Empty;
            // Subscribe to the SSE events.
            var subscription = sseObservable.Subscribe(eventData =>
            {
                if (string.IsNullOrWhiteSpace(eventData) 
                    || eventData.StartsWith("event:"))
                {
                    return;
                }

                if (eventData.StartsWith("data: "))
                {
                    eventData = eventData.Substring(6);
                }
                var response = JsonSerializer.Deserialize<ClaudeStreamingData>(eventData);
                if (response is null)
                {
                    return;
                }
                bool final = false;
                if (response.Type != "content_block_delta")
                {
                    if (response.Type == "message_stop")
                    {
                        final = true;
                    }
                    else
                    {
                        Debug.WriteLine($"Response type: {response.Type}");
                        return;
                    }
                }

                var textResponse = response?.Delta?.Text ?? string.Empty;
                workingResponse += textResponse;
                (context as ClaudeContext)!.PartialResponse += textResponse;
                if (final)
                {
                    (context as ClaudeContext)!.ContextData.Add(new ConversationItem()
                    {
                        Assistant = workingResponse,
                        User = (context as ClaudeContext)!.CurrentPrompt
                    });
                    workingResponse = string.Empty;

                    if ((context as ClaudeContext)!.CompletionCallback is not null)
                    {
                        (context as ClaudeContext)!.CompletionCallback!.Complete(Name, $"Model: {parameters.Model}", (context as ClaudeContext)!.CurrentPrompt, (context as ClaudeContext)!.PartialResponse);
                    }
                }
                receiver.ReceiveCompletionPartAsync(new ClaudeResponse()
                {
                    Context = context,
                    Response = response?.Delta?.Text ?? ""
                }, final);
            });
        }
        else
        {
            Console.WriteLine("HTTP POST request failed with status code: " + response.StatusCode);
        }
    }

    private List<ClaudeMessage> GenerateMessages(IConversationContext? context, string prompt)
    {
        var messages = new List<ClaudeMessage>();

        var ctxt = (context as ClaudeContext)!;

        if (ctxt!.ContextData.Count > 0)
        {
            foreach (var item in ctxt.ContextData)
            {
                messages.Add(new ClaudeMessage()
                {
                    Role = "user",
                    Content = item.User
                });
                messages.Add(new ClaudeMessage()
                {
                    Role = "assistant",
                    Content = item.Assistant
                });
            }
        }

        messages.Add(new ClaudeMessage()
        {
            Role = "user",
            Content = prompt
        });
        messages.Add(new ClaudeMessage()
        {
            Role = "assistant",
            Content = string.Empty
        });
        return messages;
    }

    private ClaudeParameters GenerateParameters(List<ClaudeMessage> messages, ClaudeContext? context, bool streaming)
    {
        return new ClaudeParameters()
        {
            Messages = messages,
            Stream = streaming,
            Model = _options!.Model,
            MaxTokens = 4096
        };
    }

    public IConversationContext CreateNewContext(string? systemPrompt = null)
    {
        return new ClaudeContext()
        {
            SystemPrompt = systemPrompt ?? string.Empty
        };
    }

    public async Task<List<ILLMModel>> GetModelsAsync()
    {
        var models = new List<ILLMModel>();
        models.Add(new ClaudeModel()
        {
            Name = "claude-3-5-sonnet-20240620",
            Description = "model",
            Owner = "anthropic",
            ContextWindow = 200000,
            SupportsImages = false
        });
        models.Add(new ClaudeModel()
        {
            Name = "claude-3-opus-20240229",
            Description = "model",
            Owner = "anthropic",
            ContextWindow = 1022000004,
            SupportsImages = false
        });
        models.Add(new ClaudeModel()
        {
            Name = "claude-3-sonnet-20240229",
            Description = "model",
            Owner = "anthropic",
            ContextWindow = 200000,
            SupportsImages = false
        });
        models.Add(new ClaudeModel()
        {
            Name = "claude-3-haiku-20240307",
            Description = "model",
            Owner = "anthropic",
            ContextWindow = 200000,
            SupportsImages = false
        });
        return await Task.FromResult(models);
    }
}




LLMProviders\Claude\ClaudeResponse.cs

using TalkBack.Interfaces;

namespace TalkBack.LLMProviders.Claude;

internal class ClaudeResponse : IModelResponse
{
    public IConversationContext? Context { get; set; }

    public string Response { get; set; } = string.Empty;
}




LLMProviders\Claude\ClaudeStreamingData.cs

using System.Text.Json.Serialization;

namespace TalkBack.LLMProviders.Claude;

internal class ClaudeStreamingData
{
    [JsonPropertyName("type")]
    public string? Type { get; set; }
    [JsonPropertyName("index")]
    public int? Index { get; set; }
    [JsonPropertyName("delta")]
    public ClaudeContentDelta? Delta{ get; set; }
}




LLMProviders\Groq\GroqCompletionResponse.cs

using System.Text.Json.Serialization;

namespace TalkBack.LLMProviders.Groq;

internal class GroqCompletionsResponse
{
    [JsonPropertyName("id")]
    public string? Id { get; set; }

    [JsonPropertyName("object")]
    public string? Object { get; set; }

    [JsonPropertyName("created")]
    public int Created { get; set; }

    [JsonPropertyName("model")]
    public string? Model { get; set; }

    [JsonPropertyName("choices")]
    public GroqChoice[]? Choices { get; set; }
}

internal class GroqChoice
{
    [JsonPropertyName("text")]
    public string? Text { get; set; }

    [JsonPropertyName("index")]
    public int Index { get; set; }

    [JsonPropertyName("logprobs")]
    public object? Logprobs { get; set; }

    [JsonPropertyName("finish_reason")]
    public string? FinishReason { get; set; }

    [JsonPropertyName("delta")]
    public GroqDelta? Delta { get; set; }

    [JsonPropertyName("message")]
    public GroqConversationItem? Message { get; set; }
}

internal class GroqDelta
{
    [JsonPropertyName("content")]
    public string? Content { get; set; }
}




LLMProviders\Groq\GroqContext.cs

using TalkBack.Interfaces;
using TalkBack.Models;

namespace TalkBack.LLMProviders.Groq;

internal class GroqContext : IConversationContext
{
    public List<ConversationItem> Conversation { get; set; } = new List<ConversationItem>();
    public string SystemPrompt { get; set; } = string.Empty;
    public string PartialResponse { get; set; } = string.Empty;
    public string CurrentPrompt { get; set; } = string.Empty;

    internal ICompletionCallback? CompletionCallback { get; set; } = null;
    public void SetCompletionCallback(ICompletionCallback completionCallback)
    {
        CompletionCallback = completionCallback;
    }

    public IEnumerable<ConversationItem> GetConverstationHistory()
    {
        return Conversation;
    }
}




LLMProviders\Groq\GroqConversationItem.cs

using System.Text.Json.Serialization;

namespace TalkBack.LLMProviders.Groq;

internal class GroqConversationItem
{
    public GroqConversationItem(string role, string content)
    {
        Role = role;
        Content = content;
    }
    [JsonPropertyName("role")]
    public string? Role { get; set; }
    [JsonPropertyName("content")]
    public string? Content { get; set; }
}




LLMProviders\Groq\GroqModel.cs

using System.Text.Json.Serialization;
using TalkBack.Interfaces;

namespace TalkBack.LLMProviders.Groq;

public class GroqModel : ILLMModel
{
    [JsonPropertyName("id")]
    public string? Name { get; set; }
    [JsonPropertyName("object")]
    public string? Description { get; set; }
    [JsonPropertyName("owned_by")]
    public string? Owner { get; set; }
    [JsonPropertyName("context_window")]
    public int ContextWindow { get; set; }
    public bool SupportsImages { get; set; } = false;
}





LLMProviders\Groq\GroqModelList.cs

using TalkBack.LLMProviders.OpenAI;

namespace TalkBack.LLMProviders.Groq;

public class GroqModelList
{
    public string Object { get; set; } = string.Empty;
    public GroqModel[] Data { get; set; } = Array.Empty<GroqModel>();
}




LLMProviders\Groq\GroqOptions.cs

using TalkBack.Interfaces;

namespace TalkBack.LLMProviders.Groq;

public class GroqOptions : IProviderOptions
{
    public string? ApiKey { get; set; }
    public string? Model { get; set; }
    public float Temperature { get; set; }
    public int MaxTokens { get; set; }
    public float TopP { get; set; }
    public float FrequencyPenalty { get; set; }
    public float PresencePenalty { get; set; }
    public string? Stop { get; set; }
}




LLMProviders\Groq\GroqProvider.cs

using Microsoft.Extensions.Logging;
using System.Net.Http.Headers;
using System.Net.Http.Json;
using System.Text;
using System.Text.Json;
using TalkBack.Exceptions;
using TalkBack.Interfaces;
using TalkBack.LLMProviders.OpenAI;
using TalkBack.Models;

namespace TalkBack.LLMProviders.Groq;

public class GroqProvider : ILLMProvider
{
    private const string SYSTEM = "system";
    private const string USER = "user";
    private const string ASSISTANT = "assistant";

    private readonly IHttpHandler _httpHandler;
    private readonly ILogger _logger;
    private GroqOptions? _options;

    public GroqProvider(ILogger<GroqProvider> logger, IHttpHandler httpHandler)
    {
        _logger = logger;
        _httpHandler = httpHandler;
    }

    public string Name => "Groq";

    public string Version => "1.0.0"; // Placeholder version

    public bool SupportsStreaming => true;

    // Constructor and properties

    public async Task<IModelResponse> CompleteAsync(string prompt, IConversationContext? context = null, List<ImageUrl>? imageUrls = null)
    {
        if (context is null)
        {
            context = new GroqContext();
        }
        var ocontext = context as GroqContext;
        if (ocontext is null)
        {
            throw new ArgumentException("Invalid context provided");
        }
        var request = new HttpRequestMessage(HttpMethod.Post, "https://api.groq.com/openai/v1/chat/completions")
        {
            Content = new StringContent(JsonSerializer.Serialize(new
            {
                model = _options!.Model,
                messages = BuildPrompt(prompt, context),
                stream = false
            }), Encoding.UTF8, "application/json"),
        };
        request.Headers.Add("Authorization", $"Bearer {_options.ApiKey}");
        var req = await request.Content.ReadAsStringAsync();
        using var response = await _httpHandler.SendAsync(request, HttpCompletionOption.ResponseHeadersRead);
        if (!response.IsSuccessStatusCode)
        {
            throw new InvalidOperationException($"Failure calling Groq completions endpoint. Status Code: {response.StatusCode}");
        }

        var result = await response.Content.ReadAsStringAsync();
        var completion = JsonSerializer.Deserialize<GroqCompletionsResponse>(result);
        if (completion is null)
        {
            throw new InvalidOperationException("Completion was null");
        }
        if (completion.Choices is not null && completion.Choices.Length > 0)
        {
            var responseText = completion.Choices[0].Message?.Content ?? string.Empty;
            ocontext.Conversation.Add(new ConversationItem() { User = prompt, Assistant = responseText });
            return new GroqResponse() { Response = responseText, Context = context };
        }
        _logger.LogError("Completion had no choices.");
        throw new InvalidOperationException("Completion had no choices.");
    }

    public void InitProvider(IProviderOptions? options)
    {
        _logger.LogDebug("Initializing OllamaPlugin with provided options.");
        if (options is null || options is not GroqOptions || string.IsNullOrEmpty((options as GroqOptions)!.Model))
        {
            _options = null;
            throw new InvalidOptionsException("The Groq Plugin requires an instance of the GroqOptions class with a valid Model set.");
        }
        _options = options as GroqOptions;
    }

    public async Task StreamCompletionAsync(ICompletionReceiver receiver, string prompt, IConversationContext? context = null, List<ImageUrl>? imageUrls = null)
    {
        _httpHandler.DefaultRequestHeaders.Accept.Add(new MediaTypeWithQualityHeaderValue("text/event-stream"));

        if (context is null)
        {
            context = new GroqContext();
        }
        var ocontext = context as GroqContext;
        if (ocontext is null)
        {
            throw new ArgumentException("Invalid context provided");
        }
        var request = new HttpRequestMessage(HttpMethod.Post, "https://api.groq.com/openai/v1/chat/completions")
        {
            Content = new StringContent(JsonSerializer.Serialize(new
            {
                model = _options!.Model,
                messages = BuildPrompt(prompt, context),
                stream = true
            }), Encoding.UTF8, "application/json"),
        };
        request.Headers.Add("Authorization", $"Bearer {_options.ApiKey}");
        var req = await request.Content.ReadAsStringAsync();
        var response = await _httpHandler.SendAsync(request, HttpCompletionOption.ResponseHeadersRead);

        // Set current prompt and partial response
        var oContext = (GroqContext)context;
        oContext.CurrentPrompt = prompt;
        oContext.PartialResponse = string.Empty;

        if (response.IsSuccessStatusCode)
        {
            // Read the SSE stream from the response
            var sseStream = await response.Content.ReadAsStreamAsync();

            // Handling of the SSE stream
            using var reader = new StreamReader(sseStream, Encoding.UTF8);
            while (!reader.EndOfStream)
            {
                string? line = await reader.ReadLineAsync();
                if (line == null || line == "data:[DONE]")
                {
                    break;
                }
                if (string.IsNullOrWhiteSpace(line))
                {
                    continue;
                }
                if (line.StartsWith("data:"))
                {
                    line = line.Substring(5);
                }

                // Deserialize the event data
                var eventResponse = JsonSerializer.Deserialize<GroqCompletionsResponse>(line);
                if (eventResponse == null ||
                    eventResponse.Choices is null ||
                    eventResponse.Choices.Length == 0 ||
                    eventResponse.Choices[0].Delta is null ||
                    (string.IsNullOrWhiteSpace(eventResponse.Choices[0].Delta!.Content) && string.IsNullOrWhiteSpace(eventResponse.Choices[0].FinishReason)))
                {
                    continue;
                }

                // Append to partial response
                oContext.PartialResponse += eventResponse.Choices![0].Delta!.Content;

                // Update conversation and call completion callback if done
                if (eventResponse.Choices[0].FinishReason == "stop")
                {
                    oContext.Conversation.Add(new ConversationItem { User = prompt, Assistant = oContext.PartialResponse });
                    await receiver.ReceiveCompletionPartAsync(new GroqResponse { Response = oContext.PartialResponse, Context = context }, true);
                    break;
                }
                else
                {
                    await receiver.ReceiveCompletionPartAsync(new GroqResponse { Response = eventResponse.Choices[0].Delta!.Content, Context = context }, false);
                }
            }
        }
        else
        {
            _logger.LogError($"HTTP POST request failed with status code: {response.StatusCode}");
            throw new HttpRequestException($"HTTP POST request failed with status code: {response.StatusCode}");
        }
    }

    private List<GroqConversationItem> BuildPrompt(string prompt, IConversationContext? context)
    {
        var conversation = new List<GroqConversationItem>();
        var ocontext = context as GroqContext;
        if (ocontext is null)
        {
            throw new ArgumentException("Invalid context provided");
        }

        if (_options is not null && !string.IsNullOrWhiteSpace(ocontext.SystemPrompt))
        {
            conversation.Add(new GroqConversationItem(SYSTEM, ocontext.SystemPrompt));
        }
        foreach (var conversationItem in ocontext.Conversation)
        {
            if (!string.IsNullOrWhiteSpace(conversationItem.User))
            {
                conversation.Add(new GroqConversationItem(USER, conversationItem.User));
                conversation.Add(new GroqConversationItem(ASSISTANT, conversationItem.Assistant ?? string.Empty));
            }
        }
        conversation.Add(new GroqConversationItem(USER, prompt));
        return conversation;
    }

    private GroqResponse BuildGroqResponse(string prompt, GroqCompletionsResponse result, IConversationContext? context)
    {
        var GroqResponse = new GroqResponse
        {
            Response = result.Choices![0].Text,
            Context = context as GroqContext
        };

        (GroqResponse.Context as GroqContext)!.Conversation.Add(new ConversationItem
        {
            User = prompt,
            Assistant = GroqResponse?.Response ?? ""
        });

        return GroqResponse!;
    }

    public IConversationContext CreateNewContext(string? systemPrompt = null)
    {
        return new GroqContext()
        {
            SystemPrompt = systemPrompt ?? string.Empty
        };
    }

    public async Task<List<ILLMModel>> GetModelsAsync()
    {
        var request = new HttpRequestMessage(HttpMethod.Get, "https://api.groq.com/openai/v1/models");
        request.Headers.Add("Authorization", $"Bearer {_options!.ApiKey}");
        var response = await _httpHandler.SendAsync(request, HttpCompletionOption.ResponseContentRead);
        if (!response.IsSuccessStatusCode)
        {
            throw new InvalidOperationException($"Failure calling OpenAI models endpoint. Status Code: {response.StatusCode}");
        }
        var modelList = await response.Content.ReadFromJsonAsync<GroqModelList>();
        if (modelList is null)
        {
            throw new InvalidOperationException("Model list was null");
        }
        return modelList.Data.ToList<ILLMModel>();
    }
}




LLMProviders\Groq\GroqResponse.cs

using TalkBack.Interfaces;

namespace TalkBack.LLMProviders.Groq;

internal class GroqResponse : IModelResponse
{
    public string? Response { get; set; }
    public IConversationContext? Context { get; set; }
}




LLMProviders\Ollama\OllamaCompletionResponse.cs

using System.Text.Json.Serialization;

namespace TalkBack.LLMProviders.Ollama;

internal class OllamaCompletionResponse
{
    [JsonPropertyName("model")]
    public string? Model { get; set; }

    [JsonPropertyName("created_at")]
    public string? CreatedAt { get; set; }

    [JsonPropertyName("response")]
    public string? Response { get; set; }

    [JsonPropertyName("done")]
    public bool Done { get; set; }

    [JsonPropertyName("context")]
    public int[]? Context { get; set; }

    [JsonPropertyName("total_duration")]
    public long TotalDuration { get; set; }

    [JsonPropertyName("load_duration")]
    public long LoadDuration { get; set; }

    [JsonPropertyName("prompt_eval_count")]
    public int PromptEvalCount { get; set; }

    [JsonPropertyName("prompt_eval_duration")]
    public long PromptEvalDuration { get; set; }

    [JsonPropertyName("eval_count")]
    public int EvalCount { get; set; }

    [JsonPropertyName("eval_duration")]
    public long EvalDuration { get; set; }
}




LLMProviders\Ollama\OllamaContext.cs

using TalkBack.Interfaces;
using TalkBack.Models;

namespace TalkBack.LLMProviders.Ollama;

internal class OllamaContext : IConversationContext
{
    public int[]? ContextData { get; set; }
    public List<ConversationItem> Conversation { get; set; } = new List<ConversationItem>();
    public string SystemPrompt { get; set; } = string.Empty;
    public string PartialResponse { get; set; } = string.Empty;
    public string CurrentPrompt { get; set; } = string.Empty;

    internal ICompletionCallback? CompletionCallback { get; set; } = null;
    public void SetCompletionCallback(ICompletionCallback completionCallback)
    {
        CompletionCallback = completionCallback;
    }

    public IEnumerable<ConversationItem> GetConverstationHistory()
    {
        return Conversation;
    }
}




LLMProviders\Ollama\OllamaModel.cs

using System.Text.Json.Serialization;
using TalkBack.Interfaces;

namespace TalkBack.LLMProviders.Ollama;

public class OllamaModel : ILLMModel
{
    [JsonPropertyName("name")]
    public string? Name { get; set; }

    [JsonPropertyName("digest")]
    public string? Description { get; set; }

    public string? Owner { get; set; } = "ollama";

    public int ContextWindow { get; set; } = 4096; // default value. Who knows?

    public bool SupportsImages { get; set; } = false;
}




LLMProviders\Ollama\OllamaModelList.cs

namespace TalkBack.LLMProviders.Ollama;

public class OllamaModelList
{
    public List<OllamaModel> Models { get; set; } = new List<OllamaModel>();
}




LLMProviders\Ollama\OllamaOptions.cs

using TalkBack.Interfaces;

namespace TalkBack.LLMProviders.Ollama;

public class OllamaOptions : IProviderOptions 
{
    /// <summary>
    ///  Model parameters: https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values
    /// </summary>

    // Required options
    public string? ServerUrl { get; set; }
    public string? Model { get; set; }

    // Optional options
    public int? Seed { get; set; }
    public int? NumPredict { get; set; }
    public int? TopK { get; set; }
    public float? TopP { get; set; }
    public float? Temperature { get; set; }
    public float? RepeatPenalty { get; set; }
    public float? PresencePenalty { get; set; }
    public float? FrequencyPenalty { get; set; }
}




LLMProviders\Ollama\OllamaParameters.cs

using System.Text.Json.Serialization;

namespace TalkBack.LLMProviders.Ollama;

/// <summary>
/// These are what's passed to the model.
/// </summary>
internal class OllamaParameters
{
    [JsonPropertyName("prompt")]
    public string? Prompt { get; set; }

    [JsonPropertyName("model")]
    public string? Model { get; set; }

    [JsonPropertyName("context")]
    public int[]? Context { get; set; }

    [JsonPropertyName("stream")]
    public bool? Stream { get; set; }

    [JsonPropertyName("seed")]
    public int? Seed { get; set; }

    [JsonPropertyName("num_predict")]
    public int? NumPredict { get; set; }

    [JsonPropertyName("top_k")]
    public int? TopK { get; set; }

    [JsonPropertyName("top_p")]
    public float? TopP { get; set; }

    [JsonPropertyName("temperature")]
    public float? Temperature { get; set; }

    [JsonPropertyName("repeat_penalty")]
    public float? RepeatPenalty { get; set; }

    [JsonPropertyName("presence_penalty")]
    public float? PresencePenalty { get; set; }

    [JsonPropertyName("frequency_penalty")]
    public float? FrequencyPenalty { get; set; }
}




LLMProviders\Ollama\OllamaProvider.cs

using System.Reactive.Linq;
using System.Text;
using System.Text.Json;
using TalkBack.Exceptions;
using TalkBack.Interfaces;
using TalkBack.Models;
using Microsoft.Extensions.Logging;
using System.Net.Http.Json;
using TalkBack.LLMProviders.OpenAI;

namespace TalkBack.LLMProviders.Ollama;

public class OllamaProvider : ILLMProvider
{
    private readonly ILogger<OllamaProvider> _logger;
    private readonly IHttpHandler _httpHandler;
    private OllamaOptions? _options;

    /// <summary>
    /// Ollama API docs: https://github.com/jmorganca/ollama/blob/main/docs/api.md
    /// </summary>
    public OllamaProvider(ILogger<OllamaProvider> logger, IHttpHandler httpHandler)
    {
        _logger = logger;
        _httpHandler = httpHandler;
    }

    public bool SupportsStreaming => true;

    public string Name => "Ollama";

    public void InitProvider(IProviderOptions? options)
    {
        _logger.LogDebug("Initializing OllamaPlugin with provided options.");
        _options = options as OllamaOptions;
        if (_options is null || string.IsNullOrEmpty(_options.Model) || string.IsNullOrEmpty(_options.ServerUrl))
        {
            _options = null;
            throw new InvalidOptionsException("The Ollama Plugin requires an instance of the OllamaOptions class with a valid Model and ServerUrl!");
        }
    }

    public async Task<IModelResponse> CompleteAsync(string prompt, IConversationContext? context = null, List<ImageUrl>? imageUrls = null)
    {
        if (_options is null)
        {
            throw new InvalidOperationException("You must Init the model first.");
        }
        if (context is not null && context is not OllamaContext)
        {
            throw new InvalidConversationContextException("Received an invalid context.");
        }
        var newPrompt = GeneratePrompt(context, prompt);
        OllamaParameters parameters = GenerateParameters(newPrompt, context as OllamaContext, false);
        var jsonContent = JsonSerializer.Serialize(parameters);
        var content = new StringContent(jsonContent, Encoding.UTF8, "application/json");
        var response = await _httpHandler.PostAsync(_options.ServerUrl + "/generate", content);
        var result = await response.Content.ReadAsStringAsync();

        if (context is null)
        {
            context = new OllamaContext();
        }
        var responseOb = JsonSerializer.Deserialize<OllamaCompletionResponse>(result);

        (context as OllamaContext)!.ContextData = responseOb?.Context;
        if ((context as OllamaContext)!.CompletionCallback is not null)
        {
            (context as OllamaContext)!.CompletionCallback!.Complete(Name, $"Model: {parameters.Model}", prompt, responseOb?.Response ?? string.Empty);
        }
        return new OllamaResponse()
        {
            Response = responseOb?.Response ?? string.Empty,
            Context = context
        };
    }

    public async Task StreamCompletionAsync(ICompletionReceiver receiver, string prompt, IConversationContext? context = null, List<ImageUrl>? imageUrls = null)
    {
        if (_options is null)
        {
            throw new InvalidOperationException("You must Init the model first.");
        }
        if (context is not null && context is not OllamaContext)
        {
            throw new InvalidConversationContextException("Received an invalid context.");
        }
        OllamaParameters parameters = GenerateParameters(prompt, context as OllamaContext, true);
        var jsonContent = JsonSerializer.Serialize(parameters);
        var content = new StringContent(jsonContent, Encoding.UTF8, "application/json");
        var response = await _httpHandler.PostAsync(_options.ServerUrl + "/generate", content);
        if (context is null)
        {
            context = new OllamaContext();
        }
        (context as OllamaContext)!.CurrentPrompt = GeneratePrompt(context, prompt);
        (context as OllamaContext)!.PartialResponse = string.Empty;

        if (response.IsSuccessStatusCode)
        {
            // Read the SSE stream from the response.
            var sseStream = await response.Content.ReadAsStreamAsync();

            // Create an observable sequence from the SSE stream.
            var sseObservable = Observable.Using(
                () => new StreamReader(sseStream, Encoding.UTF8),
                streamReader => Observable.Create<string>(
                    async (observer, cancellationToken) =>
                    {
                        try
                        {
                            while (!cancellationToken.IsCancellationRequested)
                            {
                                string? line = await streamReader.ReadLineAsync();
                                if (line == null)
                                    break;

                                observer.OnNext(line);
                            }
                            observer.OnCompleted();
                        }
                        catch (Exception ex)
                        {
                            observer.OnError(ex);
                        }
                    }));

            // Subscribe to the SSE events.
            var subscription = sseObservable.Subscribe(eventData =>
            {
                var response = JsonSerializer.Deserialize<OllamaCompletionResponse>(eventData);
                if (response is null)
                {
                    return;
                }
                (context as OllamaContext)!.PartialResponse += response.Response;
                if (response.Done)
                {
                    (context as OllamaContext)!.Conversation.Add(new ConversationItem()
                    {
                        Assistant = (context as OllamaContext)!.PartialResponse,
                        User = (context as OllamaContext)!.CurrentPrompt
                    });

                    if ((context as OllamaContext)!.CompletionCallback is not null)
                    {
                        (context as OllamaContext)!.CompletionCallback!.Complete(Name, $"Model: {parameters.Model}", (context as OllamaContext)!.CurrentPrompt, (context as OllamaContext)!.PartialResponse);
                    }
                    (context as OllamaContext)!.ContextData = response.Context;
                }
                receiver.ReceiveCompletionPartAsync(new OllamaResponse()
                {
                    Context = context,
                    Response = response.Response ?? ""
                }, response.Done);
            });
        }
        else
        {
            Console.WriteLine("HTTP POST request failed with status code: " + response.StatusCode);
        }
    }

    private string GeneratePrompt(IConversationContext? context, string prompt)
    {
        var ctxt = (context as OllamaContext)!;
        string newPrompt = string.Empty;
        if (ctxt.Conversation.Count > 0)
        {
            newPrompt = "You are 'Assistant'. This is the conversation so far between the user, and you;\n\n";
            foreach (var item in ctxt.Conversation)
            {
                newPrompt += $"User: {item.User} {Environment.NewLine}";
                newPrompt += $"Assistant: {item.Assistant} {Environment.NewLine}";
            }
        }

        newPrompt += "User: " + prompt;
        return newPrompt;
    }

    private OllamaParameters GenerateParameters(string prompt, OllamaContext? context, bool streaming)
    {
        return new OllamaParameters()
        {
            Prompt = prompt,
            Context = context?.ContextData,
            Stream = streaming,
            Model = _options!.Model,
            Seed = _options.Seed,
            FrequencyPenalty = _options.FrequencyPenalty,
            NumPredict = _options.NumPredict,
            PresencePenalty = _options.PresencePenalty,
            RepeatPenalty = _options.RepeatPenalty,
            Temperature = _options.Temperature,
            TopK = _options.TopK,
            TopP = _options.TopP
        };
    }

    public IConversationContext CreateNewContext(string? systemPrompt = null)
    {
        return new OllamaContext()
        {
            SystemPrompt = systemPrompt ?? string.Empty
        };
    }

    public async Task<List<ILLMModel>> GetModelsAsync()
    {
        var request = new HttpRequestMessage(HttpMethod.Get, $"{_options!.ServerUrl}/api/tags");
        var response = await _httpHandler.SendAsync(request, HttpCompletionOption.ResponseContentRead);
        if (!response.IsSuccessStatusCode)
        {
            throw new InvalidOperationException($"Failure calling OpenAI models endpoint. Status Code: {response.StatusCode}");
        }
        var modelList = await response.Content.ReadFromJsonAsync<OllamaModelList>();
        if (modelList is null)
        {
            throw new InvalidOperationException("Model list was null");
        }
        return modelList.Models.ToList<ILLMModel>();
    }
}




LLMProviders\Ollama\OllamaResponse.cs

using TalkBack.Interfaces;

namespace TalkBack.LLMProviders.Ollama;

internal class OllamaResponse : IModelResponse
{
    public IConversationContext? Context { get; set; }

    public string Response { get; set; } = string.Empty;
}




LLMProviders\OpenAI\OpenAICompletionResponse.cs

using System.Text.Json.Serialization;

namespace TalkBack.LLMProviders.OpenAI;


internal class OpenAICompletionsResponse
{

    [JsonPropertyName("id")]
    public string? Id { get; set; }

    [JsonPropertyName("object")]
    public string? Object { get; set; }

    [JsonPropertyName("created")]
    public int Created { get; set; }

    [JsonPropertyName("model")]
    public string? Model { get; set; }

    [JsonPropertyName("choices")]
    public OpenAIChoice[]? Choices { get; set; }

}

internal class OpenAIChoice
{

    [JsonPropertyName("text")]
    public string? Text { get; set; }

    [JsonPropertyName("index")]
    public int Index { get; set; }

    [JsonPropertyName("logprobs")]
    public object? Logprobs { get; set; }

    [JsonPropertyName("finish_reason")]
    public string? FinishReason { get; set; }

    [JsonPropertyName("delta")]
    public OpenAIDelta? Delta { get; set; }

    [JsonPropertyName("message")]
    public OpenAIReceivedMessage? Message { get; set; }

}

internal class OpenAIDelta
{
    [JsonPropertyName("content")]
    public string? Content { get; set; }
}



LLMProviders\OpenAI\OpenAIContext.cs

using TalkBack.Interfaces;
using TalkBack.Models;

namespace TalkBack.LLMProviders.OpenAI;

internal class OpenAIContext : IConversationContext
{
    public List<ConversationItem> Conversation { get; set; } = new List<ConversationItem>();
    public string SystemPrompt { get; set; } = string.Empty;
    public string PartialResponse { get; set; } = string.Empty;
    public string CurrentPrompt { get; set; } = string.Empty;


    internal ICompletionCallback? CompletionCallback { get; set; } = null;
    public void SetCompletionCallback(ICompletionCallback completionCallback)
    {
        CompletionCallback = completionCallback;
    }

    public IEnumerable<ConversationItem> GetConverstationHistory()
    {
        return Conversation;
    }
}



LLMProviders\OpenAI\OpenAIConversationItem.cs

using System.Text.Json;
using System.Text.Json.Serialization;
using TalkBack.Models;

namespace TalkBack.LLMProviders.OpenAI;

internal class OpenAIConversationItem
{
    public OpenAIConversationItem(string role, List<ContentItem> content)
    {
        Role = role;
        Content = content;
    }

    [JsonPropertyName("role")]
    public string? Role { get; set; }

    [JsonPropertyName("content")]
    public List<ContentItem> Content { get; set; }
}

internal class OpenAIReceivedMessage
{
    [JsonPropertyName("role")]
    public string? Role { get; set; }

    [JsonPropertyName("content")]
    public string? Content { get; set; }

}

internal class ContentItem
{
    [JsonPropertyName("type")]
    public string? Type { get; set; }

    [JsonPropertyName("text")]
    public string? Text { get; set; }

    [JsonPropertyName("image_url")]
    [JsonConverter(typeof(ImageUrlConditionalConverter))]
    public ImageUrl? ImageUrl { get; set; }
}

public class ImageUrlConditionalConverter : JsonConverter<ImageUrl?>
{
    public override ImageUrl? Read(ref Utf8JsonReader reader, Type typeToConvert, JsonSerializerOptions options)
    {
        // Implementation for reading is not needed in this case
        return null;
    }

    public override void Write(Utf8JsonWriter writer, ImageUrl? value, JsonSerializerOptions options)
    {
        if (value != null && !string.IsNullOrEmpty(value.Url))
        {
            writer.WritePropertyName("image_url");
            JsonSerializer.Serialize(writer, value);
        }
    }
}



LLMProviders\OpenAI\OpenAIModel.cs

using System.Text.Json.Serialization;
using TalkBack.Interfaces;

namespace TalkBack.LLMProviders.OpenAI;

public class OpenAIModel : ILLMModel
{
    [JsonPropertyName("id")]
    public string? Name { get; set; }

    [JsonPropertyName("object")]
    public string? Description { get; set; }

    [JsonPropertyName("owned_by")]
    public string? Owner { get; set; }

    public int ContextWindow { get; set; }

    public bool SupportsImages { get; set; } = false;
}




LLMProviders\OpenAI\OpenAIModelList.cs

namespace TalkBack.LLMProviders.OpenAI;

public class OpenAIModelList
{
    public string Object { get; set; } = string.Empty;
    public OpenAIModel[] Data { get; set; } = Array.Empty<OpenAIModel>();
}




LLMProviders\OpenAI\OpenAIOptions.cs

using TalkBack.Interfaces;

namespace TalkBack.LLMProviders.OpenAI;

public class OpenAIOptions : IProviderOptions
{
    public string? ApiKey { get; set; }
    public string? Model { get; set; }
    public float Temperature { get; set; }
    public int MaxTokens { get; set; }
    public float TopP { get; set; }
    public float FrequencyPenalty { get; set; }
    public float PresencePenalty { get; set; }
    public string? Stop { get; set; }
}




LLMProviders\OpenAI\OpenAIProvider.cs

using Microsoft.Extensions.Logging;
using System.Net.Http.Headers;
using System.Net.Http.Json;
using System.Text;
using System.Text.Json;
using TalkBack.Exceptions;
using TalkBack.Interfaces;
using TalkBack.Models;

namespace TalkBack.LLMProviders.OpenAI;

/// <summary>
/// OpenAI API docs: https://platform.openai.com/docs/api-reference
/// </summary>
public class OpenAIProvider : ILLMProvider
{
    private const string SYSTEM = "system";
    private const string USER = "user";
    private const string ASSISTANT = "assistant";

    private readonly IHttpHandler _httpHandler;
    private readonly ILogger _logger;
    private OpenAIOptions? _options;

    public OpenAIProvider(ILogger<OpenAIProvider> logger, IHttpHandler httpHandler)
    {
        _logger = logger;
        _httpHandler = httpHandler;
    }
    public string Name => "OpenAI";

    public string Version => "1.0.7";

    public bool SupportsStreaming => true;

    // Constructor and properties

    public async Task<IModelResponse> CompleteAsync(string prompt, IConversationContext? context = null, List<ImageUrl>? imageUrls = null)
    {
        if (context is null)
        {
            context = new OpenAIContext();
        }
        var ocontext = context as OpenAIContext;
        if (ocontext is null)
        {
            throw new ArgumentException("Invalid context provided");
        }
        var request = new HttpRequestMessage(HttpMethod.Post, "https://api.openai.com/v1/chat/completions")
        {
            Content = new StringContent(JsonSerializer.Serialize(new
            {
                model = _options!.Model,
                messages = BuildPrompt(prompt, context),
                stream = false
            }), Encoding.UTF8, "application/json"),
        };
        request.Headers.Add("Authorization", $"Bearer {_options.ApiKey}");
        var req = await request.Content.ReadAsStringAsync();
        using var response = await _httpHandler.SendAsync(request, HttpCompletionOption.ResponseHeadersRead);
        if (!response.IsSuccessStatusCode)
        {
            throw new InvalidOperationException($"Failure calling OpenAI completions endpoint. Status Code: {response.StatusCode}");
        }

        var result = await response.Content.ReadAsStringAsync();
        var completion = JsonSerializer.Deserialize<OpenAICompletionsResponse>(result);
        if (completion is null)
        {
            throw new InvalidOperationException("Completion was null");
        }
        if (completion.Choices is not null && completion.Choices.Length > 0)
        {
            var responseText = completion.Choices[0].Message?.Content ?? string.Empty;
            ocontext.Conversation.Add(new ConversationItem() { User = prompt, Assistant = responseText });
            return new OpenAIResponse() { Response = responseText, Context = context };
        }
        _logger.LogError("Completion had no choices.");
        throw new InvalidOperationException("Completion had no choices.");
    }

    public void InitProvider(IProviderOptions? options)
    {
        _logger.LogDebug("Initializing OllamaPlugin with provided options.");
        if (options is null || options is not OpenAIOptions || string.IsNullOrEmpty((options as OpenAIOptions)!.Model))
        {
            _options = null;
            throw new InvalidOptionsException("The OpenAi Plugin requires an instance of the OpenAIOptions class with a valid Model set.");
        }
        _options = options as OpenAIOptions;
    }

    public async Task StreamCompletionAsync(ICompletionReceiver receiver, string prompt, IConversationContext? context = null, List<ImageUrl>? imageUrls = null)
    {
        _httpHandler.DefaultRequestHeaders.Accept.Add(new MediaTypeWithQualityHeaderValue("text/event-stream"));

        if (context is null)
        {
            context = new OpenAIContext();
        }
        var ocontext = context as OpenAIContext;
        if (ocontext is null)
        {
            throw new ArgumentException("Invalid context provided");
        }
        var content = JsonSerializer.Serialize(new
        {
            model = _options!.Model,
            messages = BuildPrompt(prompt, context),
            stream = true
        }).Replace(",\"image_url\":null", "");


        var request = new HttpRequestMessage(HttpMethod.Post, "https://api.openai.com/v1/chat/completions")
        {
            Content = new StringContent(content , Encoding.UTF8, "application/json"),
        };
        request.Headers.Add("Authorization", $"Bearer {_options.ApiKey}");
        var req = await request.Content.ReadAsStringAsync();
        var response = await _httpHandler.SendAsync(request, HttpCompletionOption.ResponseHeadersRead);

        // Set current prompt and partial response
        var oContext = (OpenAIContext)context;
        oContext.CurrentPrompt = prompt;
        oContext.PartialResponse = string.Empty;

        if (response.IsSuccessStatusCode)
        {
            // Read the SSE stream from the response
            var sseStream = await response.Content.ReadAsStreamAsync();

            // Handling of the SSE stream
            using var reader = new StreamReader(sseStream, Encoding.UTF8);
            while (!reader.EndOfStream)
            {
                string? line = await reader.ReadLineAsync();
                if (line == null || line == "data:[DONE]")
                {
                    break;
                }
                if (string.IsNullOrWhiteSpace(line))
                {
                    continue;
                }
                if (line.StartsWith("data:"))
                {
                    line = line.Substring(5);
                }

                // Deserialize the event data
                var eventResponse = JsonSerializer.Deserialize<OpenAICompletionsResponse>(line);
                if (eventResponse == null || 
                    eventResponse.Choices is null || 
                    eventResponse.Choices.Length == 0 || 
                    eventResponse.Choices[0].Delta is null ||
                    (string.IsNullOrWhiteSpace(eventResponse.Choices[0].Delta!.Content) && string.IsNullOrWhiteSpace(eventResponse.Choices[0].FinishReason)))
                {
                    continue;
                }

                // Append to partial response
                oContext.PartialResponse += eventResponse.Choices![0].Delta!.Content;

                // Update conversation and call completion callback if done
                if (eventResponse.Choices[0].FinishReason == "stop")
                {
                    oContext.Conversation.Add(new ConversationItem { User = prompt, Assistant = oContext.PartialResponse });
                    await receiver.ReceiveCompletionPartAsync(new OpenAIResponse { Response = oContext.PartialResponse, Context = context }, true);
                    break;
                }
                else
                {
                    await receiver.ReceiveCompletionPartAsync(new OpenAIResponse { Response = eventResponse.Choices[0].Delta!.Content, Context = context }, false);
                }
            }
        }
        else
        {
            _logger.LogError($"HTTP POST request failed with status code: {response.StatusCode}");
            throw new HttpRequestException($"HTTP POST request failed with status code: {response.StatusCode}");
        }
    }

    private List<OpenAIConversationItem> BuildPrompt(string prompt, IConversationContext? context)
    {
        var conversation = new List<OpenAIConversationItem>();
        var ocontext = context as OpenAIContext;
        if (ocontext is null)
        {
            throw new ArgumentException("Invalid context provided");
        }

        if (_options is not null && !string.IsNullOrWhiteSpace(ocontext.SystemPrompt))
        {
            conversation.Add(new OpenAIConversationItem(SYSTEM, ContentFromString(ocontext.SystemPrompt)));
        }
        foreach(var conversationItem in ocontext.Conversation)
        {
            if (!string.IsNullOrWhiteSpace(conversationItem.User))
            {
                if (conversationItem.ImageUrls is not null && conversationItem.ImageUrls.Count > 0)
                {
                    conversation.Add(new OpenAIConversationItem(USER, ContentFromStringAndImages(conversationItem.User, conversationItem.ImageUrls)));
                }
                else
                {
                    conversation.Add(new OpenAIConversationItem(USER, ContentFromString(conversationItem.User)));
                }
                conversation.Add(new OpenAIConversationItem(USER, ContentFromString(conversationItem.User)));
                conversation.Add(new OpenAIConversationItem(ASSISTANT, ContentFromString(conversationItem.Assistant ?? string.Empty)));
            }
        }
        conversation.Add(new OpenAIConversationItem(USER, ContentFromString(prompt)));
        return conversation;
    }

    private List<ContentItem> ContentFromString(string text)
    {
        return new List<ContentItem>() { new ContentItem { Type = "text", Text  = text} };
    }
    private List<ContentItem> ContentFromStringAndImages(string text, List<ImageUrl> imageUrls)
    {
        var content = ContentFromString(text);
        foreach (var imageUrl in imageUrls)
        {
            content.Add(new ContentItem { Type = "image_url", ImageUrl = new ImageUrl() { Url = imageUrl.Url, Detail = imageUrl.Detail } });
        }
        return content;
    }


    private OpenAIResponse BuildOpenAIResponse(string prompt, OpenAICompletionsResponse result, IConversationContext? context)
    {
        var openAIResponse = new OpenAIResponse
        {
            Response = result.Choices![0].Text,
            Context = context as OpenAIContext
        };

        (openAIResponse.Context as OpenAIContext)!.Conversation.Add(new ConversationItem
        {
            User = prompt,
            Assistant = openAIResponse?.Response ?? ""
        });

        return openAIResponse!;
    }

    public IConversationContext CreateNewContext(string? systemPrompt = null)
    {
        return new OpenAIContext()
        {
            SystemPrompt = systemPrompt ?? string.Empty
        };
    }

    public async Task<List<ILLMModel>> GetModelsAsync()
    {
        var request = new HttpRequestMessage(HttpMethod.Get, "https://api.openai.com/v1/models");
        request.Headers.Add("Authorization", $"Bearer {_options!.ApiKey}");
        var response = await _httpHandler.SendAsync(request, HttpCompletionOption.ResponseContentRead);
        if (!response.IsSuccessStatusCode)
        {
            throw new InvalidOperationException($"Failure calling OpenAI models endpoint. Status Code: {response.StatusCode}");
        }
        var modelList = await response.Content.ReadFromJsonAsync<OpenAIModelList>();
        if (modelList is null)
        {
            throw new InvalidOperationException("Model list was null");
        }
        return modelList.Data.Select(m => PreprocessModel(m)).ToList<ILLMModel>();
    }

    private OpenAIModel PreprocessModel(OpenAIModel m)
    {
        switch(m.Name)
        {
            case "gpt-4o":
            case "gpt-4o-mini":
            case "gpt-4o-mini-2024-07-18":
            case "gpt-4o-2024-05-13":
            case "gpt-4o-2024-08-06":
            case "chatgpt-4o-latest":
            case "gpt-4-turbo":
            case "gpt-4-turbo-2024-04-09":
            case "gpt-4-turbo-preview":
            case "gpt-4-0125-preview":
            case "gpt-4-1106-preview":
                m.ContextWindow = 128000;
                m.SupportsImages = true;
                break;
            case "gpt-4":
            case "gpt-4-0613":
            case "gpt-4-0314":
                m.ContextWindow = 8192;
                m.SupportsImages = true;
                break;
            case "gpt-3.5-turbo-0125":
            case "gpt-3.5-turbo":
            case "gpt-3.5-turbo-1106":
                m.ContextWindow = 16385;
                m.SupportsImages = false;
                break;
            default:
                m.ContextWindow = 4096;
                m.SupportsImages = false;
                break;
        }
        return m;
    }
}




LLMProviders\OpenAI\OpenAIResponse.cs

using TalkBack.Interfaces;

namespace TalkBack.LLMProviders.OpenAI;

internal class OpenAIResponse : IModelResponse
{
    public string? Response { get; set; }
    public IConversationContext? Context { get; set; }
}




Models\ConversationItem.cs

namespace TalkBack.Models;

public class ConversationItem
{
    public string User { get; set; }  = string.Empty;
    public string Assistant { get; set; } = string.Empty;
    public List<ImageUrl>? ImageUrls { get; set; } = null;
}




Models\ImageUrl.cs

using System.Text.Json.Serialization;

namespace TalkBack.Models;

public class ImageUrl
{
    [JsonPropertyName("url")]
    public string? Url { get; set; } = string.Empty;
    [JsonPropertyName("detail")]
    public string? Detail { get; set; } = string.Empty;
}




Utility\HttpHandler.cs

using System.Net;
using System.Net.Http.Headers;
using TalkBack.Interfaces;

namespace TalkBack.Utility;

public class HttpHandler : IHttpHandler
{
    private readonly HttpClient _client;
    public HttpHandler(IHttpClientFactory clientFactory)
    {
        _client = clientFactory.CreateClient();
    }

    public HttpRequestHeaders DefaultRequestHeaders
    {
        get
        {
            return _client.DefaultRequestHeaders;
        }
    }

    public HttpResponseMessage Get(string url)
    {
        return GetAsync(url).Result;
    }

    public HttpResponseMessage Post(string url, HttpContent content)
    {
        return PostAsync(url, content).Result;
    }

    public async Task<HttpResponseMessage> GetAsync(string url)
    {
        return await _client.GetAsync(url);
    }

    public async Task<HttpResponseMessage> PostAsync(string url, HttpContent content)
    {
        return await _client.PostAsync(url, content);
    }

    public async Task<HttpResponseMessage> SendAsync(HttpRequestMessage msg, HttpCompletionOption completion)
    {
        return await _client.SendAsync(msg, completion);
    }
}




Utility\TalkBackServiceRegistration.cs

using Microsoft.Extensions.DependencyInjection;
using TalkBack.Interfaces;
using TalkBack.LLMProviders.Ollama;
using TalkBack.LLMProviders.OpenAI;
using TalkBack.LLMProviders.Claude;
using TalkBack.LLMProviders.Groq;

namespace TalkBack.Utility;


public static class TalkBackServiceRegistration
{
    public static IServiceCollection RegisterTalkBack(this IServiceCollection services)
    {
        // Register dependencies required by TalkBack
        services.AddHttpClient();

        services.AddTransient<IProviderActivator, ProviderActivator>();
        services.AddTransient<ILLM, LLM>();
        services.AddTransient<IHttpHandler, HttpHandler>();

        services.AddTransient(typeof(OllamaProvider));
        services.AddTransient(typeof(OpenAIProvider));
        services.AddTransient(typeof(GroqProvider));
        services.AddTransient(typeof(ClaudeProvider));

        return services;
    }
}





